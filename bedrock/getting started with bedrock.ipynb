{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d79129ec-f754-447a-86af-a182e7271d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca8a64d-b3a4-4d7f-8891-3535f847de8f",
   "metadata": {},
   "source": [
    "# Working with Bedrock\n",
    "\n",
    "Until now, I have worked with OpenAI's API. I wanted to learn to use Bedrock. I came across the the website [AWS in plain English](https://aws.plainenglish.io/). They had blogs on connecting to Bedrock. So I wanted to try it out. Here is my attempt.\n",
    "\n",
    "## Gotchas\n",
    "Bedrock was not available as a client in `langchain`. Even when I did `pip install boto3 --upgrade`, it would not work. So I had to do the following:\n",
    "\n",
    "1. Shut down Jupyter.\n",
    "2. Uninstall `boto3` and `botocore`\n",
    "3. Re-install `boto3` \n",
    "4. Launch Jupyter notebook\n",
    "\n",
    "I used 2 different blog articles for working on this code.\n",
    "\n",
    "* [_Getting Started with Bedrock_ blog](https://medium.com/@charlesdouglas_96859/getting-started-with-aws-bedrock-33eee356af72) article helped me setup the basic authentication and issue a simple request to Claude. \n",
    "* For the RAG implementation with Bedrock, I used the blog, [Chat with your data..](https://aws.plainenglish.io/chat-with-your-data-a-simple-guide-using-amazon-bedrock-langchain-and-streamlit-2d60ea857eaf).\n",
    "\n",
    "The document I am summarizing is a paper from Anthropic called [Consutitutional AI: Harmlessness from AI Feedback](https://arxiv.org/pdf/2212.08073.pdf). \n",
    "\n",
    "My ideal end-goal is to convert this to some kind of a Lambda code which can accept user input and respond back with the AI generated response. For this, I'll probably refer to the [Intelligent Document Processing](https://aws.amazon.com/blogs/machine-learning/intelligent-document-processing-with-amazon-textract-amazon-bedrock-and-langchain/) AWS blog.\n",
    "\n",
    "## Bedrock with Boto3\n",
    "\n",
    "The following code just tries to connect to Bedrock and list the available models. The purpose of this code is to ensure that `boto3` is able to read the credentials and Bedrock is accessible for this user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e8343a8b-e985-49ff-b7ed-cba8f941d4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Bedrock client\n",
    "# although they say that boto3.client('bedrock') is possible, it would not work for me. I had to break it to 2 steps.\n",
    "session = boto3.Session(profile_name='aws_sol')\n",
    "bedrock = session.client('bedrock') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60153a99-9589-4bcf-ab7d-721233912a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = bedrock.list_foundation_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e71615b9-47e1-4af2-a8fe-5f334d6f0662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titan Text Large\n",
      "Titan Image Generator G1\n",
      "Titan Image Generator G1\n",
      "Titan Text Embeddings v2\n",
      "Titan Text G1 - Lite\n",
      "Titan Text G1 - Lite\n",
      "Titan Text G1 - Express\n",
      "Titan Text G1 - Express\n",
      "Titan Embeddings G1 - Text\n",
      "Titan Embeddings G1 - Text\n",
      "Titan Multimodal Embeddings G1\n",
      "Titan Multimodal Embeddings G1\n",
      "SDXL 0.8\n",
      "SDXL 0.8\n",
      "SDXL 1.0\n",
      "SDXL 1.0\n",
      "J2 Grande Instruct\n",
      "J2 Jumbo Instruct\n",
      "Jurassic-2 Mid\n",
      "Jurassic-2 Mid\n",
      "Jurassic-2 Ultra\n",
      "Jurassic-2 Ultra\n",
      "Claude Instant\n",
      "Claude Instant\n",
      "Claude\n",
      "Claude\n",
      "Claude\n",
      "Claude\n",
      "Claude\n",
      "Claude\n",
      "Claude\n",
      "Command\n",
      "Command\n",
      "Command Light\n",
      "Command Light\n",
      "Embed English\n",
      "Embed Multilingual\n",
      "Llama 2 Chat 13B\n",
      "Llama 2 Chat 13B\n",
      "Llama 2 Chat 70B\n",
      "Llama 2 Chat 70B\n",
      "Llama 2 13B\n",
      "Llama 2 13B\n",
      "Llama 2 70B\n",
      "Llama 2 70B\n"
     ]
    }
   ],
   "source": [
    "for model in resp['modelSummaries']:\n",
    "    print(model['modelName'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87ef83b-7760-4f55-810b-d0e84ae5769b",
   "metadata": {},
   "source": [
    "## Step 2: Test a prompt with Claude\n",
    "\n",
    "Again, I am relying on `boto3`. The idea here is to test if Claude is accessible and can respond to user queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4382b45-bd8e-4550-8922-a186edc1cd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hello! I'm Claude, an AI assistant created by Anthropic. I don't actually have personal preferences or experiences to share, since I'm an AI without subjective experiences. I'm designed to be helpful, harmless, and honest through conversations like this.\n"
     ]
    }
   ],
   "source": [
    "# checking if I can invoke Anthropic Claude\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "bedrock = session.client(service_name='bedrock-runtime', region_name='us-east-1')\n",
    "\n",
    "modelId = 'anthropic.claude-v2'\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "body = json.dumps({\n",
    "    \"prompt\": \"Human:This is a test prompt. Assistant:\",\n",
    "    \"max_tokens_to_sample\": 300,\n",
    "    \"temperature\": 0.1,\n",
    "    \"top_p\": 0.9,\n",
    "})\n",
    "\n",
    "response = bedrock.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "\n",
    "response_body = json.loads(response.get('body').read())\n",
    "\n",
    "print(response_body.get('completion'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9642e12-a7cf-4c79-9aeb-b6a74db28184",
   "metadata": {},
   "source": [
    "## Step 3: RAG implementation with Bedrock\n",
    "\n",
    "For a RAG implementation, I am doing the following:\n",
    "\n",
    "1. Setting up a runtime model as Anthropic-Claude (`anthropic.claude-v2`)\n",
    "2. Using a fixed PDF as the document\n",
    "3. Chroma as my vector database\n",
    "4. Anthropic-Claude to generate vector embeddings and the AI model\n",
    "\n",
    "In the [reference blog](https://aws.plainenglish.io/chat-with-your-data-a-simple-guide-using-amazon-bedrock-langchain-and-streamlit-2d60ea857eaf), they mention the use of `DirectoryLoader`. When I tried it, I kept running into library issues with `unstructured`. After fixing it, I realized that Chroma database does not support such data structures. Hence I reverted back to using a single PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da02deb1-179c-48b1-922e-a097b148b665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain.embeddings import BedrockEmbeddings\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "#from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f1de991-ca84-4b12-bd4e-363cfc5002d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the boto session and the model to be used. My AWS profile `aws_sol` is stored in the ~/.aws/credentials file.\n",
    "# When using with Okta, use [Okta-CLI](https://github.com/okta/okta-aws-cli) to generate temporary credentials.\n",
    "\n",
    "session = boto3.Session(profile_name='aws_sol')\n",
    "bedrock_runtime = session.client(\n",
    "    service_name = \"bedrock-runtime\",\n",
    "    region_name = \"us-east-1\"\n",
    ")\n",
    "\n",
    "modelId = 'anthropic.claude-v2'\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "body = json.dumps({\n",
    "    \"max_tokens_to_sample\": 40000,\n",
    "    \"temperature\": 0.1,\n",
    "    \"top_p\": 0.9,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79be68b0-3a07-4eba-bdeb-fcb35ebbceb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the directory containing the PDF files (example_data folder).\n",
    "file = './data/2212.08073.pdf'\n",
    "\n",
    "# Function to load documents from the specified directory.\n",
    "def load_docs(file):\n",
    "    # Create an instance of the DirectoryLoader with the provided directory path.\n",
    "    loader = PyPDFLoader(file)\n",
    "    # Use the loader to load the documents from the directory and store them in 'documents'.\n",
    "    documents = loader.load()\n",
    "    # Return the loaded documents.\n",
    "    return documents\n",
    "\n",
    "\n",
    "# Call the load_docs function to retrieve the documents from the specified directory.\n",
    "documents = load_docs(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "500dae0a-9ef9-4bed-bb33-93993728dc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split the loaded documents into semantically separate chunks.\n",
    "def split_docs(documents, chunk_size=256, chunk_overlap=25):\n",
    "    # Create an instance of the RecursiveCharacterTextSplitter with specified chunk size and overlap.\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    # Use the text splitter to split the documents into chunks and store them in 'docs'.\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "    # Return the split documents.\n",
    "    return docs\n",
    "\n",
    "# Call the split_docs function to break the loaded documents into chunks.\n",
    "# The chunk_size and chunk_overlap parameters can be adjusted based on specific requirements.\n",
    "docs = split_docs(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63085a94-f6a0-471e-a0f5-9a1d1a66cefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Bedrock(\n",
    "    model_id=modelId,\n",
    "    client=bedrock_runtime\n",
    ")\n",
    "bedrock_embeddings = BedrockEmbeddings(client=bedrock_runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0e42137-1677-46f1-9ac6-14207065a313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the data to Chroma DB\n",
    "db = Chroma.from_documents(documents=docs,embedding=bedrock_embeddings,persist_directory='./data')\n",
    "db.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36748f47-f3bb-4cb2-8e30-3f2ee5edbc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now run a query based on the paper\n",
    "chain = load_qa_chain(llm, chain_type = \"stuff\")\n",
    "query = \"What the argument for using a constitutional AI?\"\n",
    "docs = db.similarity_search(query)\n",
    "resp = chain.run(input_documents = docs, question = query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f4e2d629-1af3-4e4b-8f53-eafa829a7178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Based on the provided context, the main argument for using a constitutional AI seems to be that it allows the AI system to be developed in a simple, transparent, and controllable way that makes it easier to understand and evaluate its decision-making. Specifically:\n",
      "\n",
      "- The constitution consists of human-written principles that guide the AI system's development and behavior. This allows human values and preferences to be directly encoded.\n",
      "\n",
      "- The constitutional approach results in an AI system with a simple and transparent form. This makes it easier to understand how the system makes decisions. \n",
      "\n",
      "- Setting constraints via the constitution allows the developers to control aspects of the AI system's behavior (e.g. adopting a certain persona). This makes the system's behavior more predictable and controllable.\n",
      "\n",
      "- Having an explicit constitution makes it easier to study how different AI behaviors generalize. The developers can directly modify the constitution and evaluate the impacts.\n",
      "\n",
      "So in summary, the main argument seems to be that the constitutional AI approach enables simplicity, transparency, controllability, and evaluability compared to other AI development methods.\n"
     ]
    }
   ],
   "source": [
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78135a74-f81f-475d-963c-a4274d76064a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try a query where the model or the paper may not have correct response\n",
    "chain = load_qa_chain(llm, chain_type = \"stuff\")\n",
    "query = \"What the primary issues with RLFHM?\"\n",
    "docs = db.similarity_search(query)\n",
    "resp = chain.run(input_documents = docs, question = query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1db6d19-a8ef-4028-88b4-e3f19dd41295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I do not have enough context to determine the primary issues with RLFHM. The details provided mention it was evaluated on prompts from Thoppilan et al. 2022 and includes responses from HH RLHF models, but do not specify what RLFHM refers to or what issues were found during evaluation. Without more specifics on the model, training approach, and evaluation results, I cannot confidently summarize the primary issues. I would need more context about the evaluation and model details to provide a helpful answer.\n"
     ]
    }
   ],
   "source": [
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98448162-3066-45f5-8ab0-1f1d2e5f0a77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
