{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80c75fa8-725f-4af0-b0e7-07a3d6d5cb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools, initialize_agent, AgentType\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "# decorator\n",
    "from langchain.agents import tool\n",
    "import requests\n",
    "import tempfile\n",
    "from langchain.document_loaders import BSHTMLLoader\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a304be39-8140-4b40-9bda-810f1e38fe34",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_latest_page(text: str) -> str:\n",
    "    '''Accesses a URL that is provided as a string, extracts the text content and returns this content as a string as well. \n",
    "    '''\n",
    "    try:\n",
    "        resp = requests.get(text)\n",
    "\n",
    "        with tempfile.NamedTemporaryFile(delete=False) as fp:\n",
    "            fp.write(resp.content)\n",
    "            fp.close()\n",
    "\n",
    "            loader = BSHTMLLoader(fp.name)\n",
    "            data = loader.load() \n",
    "            resp = data[0].page_content\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        resp = ''\n",
    "    \n",
    "    return resp"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a22b8edb-c932-4204-961c-ee1a9742058f",
   "metadata": {},
   "source": [
    "print(get_latest_page('https://akshayranganath.github.io/')[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d9fa07e-8845-48b6-976c-c72159f16213",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1be24b25-d844-44d4-a7dc-90bc03552867",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools(['llm-math'], llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ff41ba3-3825-40cd-855b-d9cfbd58da2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools += [get_latest_page]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b42b2441-26db-4be0-9c5a-b0cd3063650f",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f560dc6d-b865-40e0-9c7f-8c6ef3cb12f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent = AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    memory = memory,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f68f75d-4258-403d-906c-52b762b05e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to extract the contents of the webpage and then generate a summary of the text. I can use the get_latest_page tool to access the URL and get the text content.\n",
      "Action: get_latest_page\n",
      "Action Input: \"https://techstrong.ai/aiops/the-rise-of-shadow-ai/\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Rise of Shadow AI - Techstrong.ai\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skip to content\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Toggle NavigationLatestArticlesFeaturesNewsVideosRelated SitesTechstrong GroupContainer JournalSecurity BoulevardDigital CxOTechstrong ResearchDevOps ChatDevOps DozenDevOps TVTechstrong TVTechstrong TV PodcastTechstrong TV TwitchAboutMedia Kit \n",
      "\n",
      "\n",
      "Search for:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Toggle NavigationAI at the EdgeAI CareersBuilding With AIConversational AICybersecurity AIData EngineeringData ScienceMoreAerospaceAIOpsGenerative AIGovernmentMachine/Deep LearningPrompt EngineeringTransportation/Travel\n",
      "\n",
      " \n",
      "\n",
      "Home » The Rise of Shadow AIThe Rise of Shadow AIPublished On: July 5, 2023By John Willis\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "“Before AI is smarter than us, I think the people developing it should be encouraged to put a lot of work into understanding how it might try and take control away,” – Geoffrey Hinton, Godfather of A.I.\n",
      "\n",
      "The rise of Generative AI and ChatGPT is leading to a new version of Shadow IT with increased security and compliance risks.\n",
      "Generative AI large language models are complex and opaque, with few experts understanding how they work, leading to increased security risks.\n",
      "Organizations must learn to manage the increased risks of using open source software in generative AI solutions.\n",
      "IT leaders need to implement standardized internal training programs, standardize the use of LLMs and develop secure LLM delivery workflows.\n",
      "New policies and observability patterns must be developed to consider vulnerability scans of LLM code and dependencies and detect anomalies, breaches and data leaks.\n",
      "Recent innovations like retrieval augmentation tools have reduced LLM hallucinations and allowed for safer use of generative AI by organizations.\n",
      "IT leadership must invest in training and human development to effectively manage these new generative AI business opportunities.\n",
      "\n",
      "With the rise of ChatGPT and generative AI, we’re experiencing a new version of “Shadow IT.” This time, the stakes are higher. Shadow IT, such as unauthorized use of cloud computing, posed significant security and compliance risks, regulatory violations, bypassed security and caused enormous technical debt. Generative AI large language models are much more complex and opaque than cloud computing at the time. Generative AI is similar to cloud computing a decade ago in that it is new and rapidly evolving. Modern use patterns for cloud computing support were well-known in most organizations. This domain was at least familiar to IT leaders at the time. You could say only the names were changed. \n",
      "For example, all cloud computing complexities were based on well-known IT primitives such as network, storage and computation. Few experts understand how generative AI works, but like cloud computing, many people in the business will be participating. Previously, only data scientists worked closely with these complex AI models. There is now a new category of citizen data scientists. Everyone can use complex technologies with a tool like ChatGPT. Shadow AI will significantly increase data and privacy breaches, model poisoning, plagiarism, and copyright infringement if allowed to sprawl and be unmanaged. The system’s opacity will undoubtedly raise new security concerns.\n",
      "\n",
      "Sponsorships Available\n",
      "\n",
      "\n",
      "Due to a bug in the Redis client open source library, ChatGPT allowed some users to view titles from another active user’s chat history in March 2023. ChatGPT Plus subscribers’ payment-related information may have been unintentionally visible due to the same bug. Asyncio (an asynchronous I/O library) was the source of the Redis bug. Essentially, generative AI solutions like LLMs use a lot of open sources, and organizations must be prepared to manage these increased risks. This is especially true if an organization needs more time to be ready to deal with the new Shadow AI effect.\n",
      "Managing Shadow AI\n",
      "Even though DevOps didn’t solve shadow IT completely, it led to secure pipelines and improved manageability for delivering cloud-native and business transformative solutions. The introduction of DevOps smoothed out the impact of increased demand from all parts of the company. Like DevOps in the early days, IT leaders must learn to manage these new organizational AI business opportunities. Consequently, IT leaders will need to address the following for Shadow AI across the organization:\n",
      "\n",
      "Implement standardized internal training programs with extensive train-the-trainer courses.\n",
      "Standardize the use of LLMs within your organization.\n",
      "Create domain-driven design patterns for different AI retrieval models using standard APIs. For example, something like LangChain is very promising.\n",
      "Share and reuse LLMs from common source repositories. Model code, notebooks and infrastructure must be stored the same way as application source code in GIT models.\n",
      "A Secure LLM delivery concept must be developed. Some have already labeled these LLMOps. \n",
      "Organizations must learn to manage commit to deploy to operations. Although MLOps can teach us much, LLMs have a different delivery structure.\n",
      "Secure LLM delivery workflows will require new policies to consider vulnerability scans of LLM code and dependencies; a new umbrella of security awareness will need to be developed.\n",
      "New observability patterns need to be developed to detect anomalies, breaches and leaks of data.\n",
      "\n",
      "Good News\n",
      "Fortunately, there are some positive developments. generative AI and LLM training has been explosive, and it’s getting easier to aggregate this complexity into more straightforward in-house training solutions. Although most training modules aren’t intended for enterprise use, there are enough to assemble a team of trainers. OpenAI will no longer default to using customer data for training its models. Data submitted through ChatGPT’s API, including training AI models, will no longer be used by OpenAI by March 2023. Moreover, the company is implementing a 30-day data retention policy for API users, with options for stricter retention based on user needs, simplifying its terms and ensuring users own their data. The Azure OpenAI program promises additional safeguards and protections and what they call responsible AI principles. Many new LLM tools, including Google, Facebook, and countless others, are creating tools daily. Like the evolution of cloud computing and DevOps, all the LLM applications will get better over time and more secure as we learn and drive more enterprise innovation.\n",
      "Recent innovations have also reduced LLM hallucinations in retrieval augmentation tools. Organizations can retrieve relevant information from user-supplied knowledge bases by using Langchain and AI vector databases. These tools do not rely on the already trained models but on user-defined text and user-supplied embeddings. Risk controls and compliance-monitored data could be passed into an LLM so that internal organizations could take advantage of generative AI without exposing themselves to the risk of compromising internal information.\n",
      "Summary\n",
      "These new business opportunities must be managed by IT leadership. As a result of those new software architectures, cloud-native development models and emerging delivery solutions like DevOps, commerce has experienced enormous success over the past decade. C-level IT leadership invested heavily in training and human development to achieve that success. These new generative AI opportunities need to be seen similarly by leaders now. Let’s not make the same mistakes again!\n",
      " \n",
      "\n",
      "SHARE THIS STORY\n",
      "\n",
      "RELATED STORIES:\n",
      "What is LangChain and Why all the Rage?\n",
      "Successful Generative AI Deployment Strategies\n",
      "Understanding Prompt Engineering\n",
      "HPE Expands Managed GreenLake Service to Include LLMs\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "FOLLOW USNEWSLETTER SIGN UP\n",
      "©  Techstrong Group, Inc. ALL RIGHTS RESERVED.\n",
      "\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "Page load link\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Go to Top\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[0m\n",
      "Thought:"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "An output parsing error occurred. In order to pass this error back to the agent and have it try again, pass `handle_parsing_errors=True` to the AgentExecutor. This is the error: Could not parse LLM output: `I have successfully extracted the contents of the webpage.\nAction: None`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "File \u001b[0;32m~/Projects/idea/yolov5/venv/lib/python3.10/site-packages/langchain/agents/agent.py:933\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Projects/idea/yolov5/venv/lib/python3.10/site-packages/langchain/agents/agent.py:547\u001b[0m, in \u001b[0;36mAgent.plan\u001b[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m full_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_chain\u001b[38;5;241m.\u001b[39mpredict(callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfull_inputs)\n\u001b[0;32m--> 547\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_output\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/idea/yolov5/venv/lib/python3.10/site-packages/langchain/agents/mrkl/output_parser.py:70\u001b[0m, in \u001b[0;36mMRKLOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m re\u001b[38;5;241m.\u001b[39msearch(\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms]*Action\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*Input\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md*\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*:[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms]*(.*)\u001b[39m\u001b[38;5;124m\"\u001b[39m, text, re\u001b[38;5;241m.\u001b[39mDOTALL\n\u001b[1;32m     69\u001b[0m ):\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not parse LLM output: `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     72\u001b[0m         observation\u001b[38;5;241m=\u001b[39mMISSING_ACTION_INPUT_AFTER_ACTION_ERROR_MESSAGE,\n\u001b[1;32m     73\u001b[0m         llm_output\u001b[38;5;241m=\u001b[39mtext,\n\u001b[1;32m     74\u001b[0m         send_to_llm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     75\u001b[0m     )\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mOutputParserException\u001b[0m: Could not parse LLM output: `I have successfully extracted the contents of the webpage.\nAction: None`",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCan you extract the contents of this webpage https://techstrong.ai/aiops/the-rise-of-shadow-ai/ and then generate a summary of the extracted text?\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/idea/yolov5/venv/lib/python3.10/site-packages/langchain/chains/base.py:505\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    504\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supports only one positional argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 505\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[1;32m    506\u001b[0m         _output_key\n\u001b[1;32m    507\u001b[0m     ]\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(kwargs, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[1;32m    511\u001b[0m         _output_key\n\u001b[1;32m    512\u001b[0m     ]\n",
      "File \u001b[0;32m~/Projects/idea/yolov5/venv/lib/python3.10/site-packages/langchain/chains/base.py:310\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    309\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    311\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    312\u001b[0m final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    313\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    314\u001b[0m )\n",
      "File \u001b[0;32m~/Projects/idea/yolov5/venv/lib/python3.10/site-packages/langchain/chains/base.py:304\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    297\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[1;32m    298\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    299\u001b[0m     inputs,\n\u001b[1;32m    300\u001b[0m     name\u001b[38;5;241m=\u001b[39mrun_name,\n\u001b[1;32m    301\u001b[0m )\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    303\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 304\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    307\u001b[0m     )\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    309\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/Projects/idea/yolov5/venv/lib/python3.10/site-packages/langchain/agents/agent.py:1146\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[0;32m-> 1146\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[1;32m   1154\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(\n\u001b[1;32m   1155\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[38;5;241m=\u001b[39mrun_manager\n\u001b[1;32m   1156\u001b[0m         )\n",
      "File \u001b[0;32m~/Projects/idea/yolov5/venv/lib/python3.10/site-packages/langchain/agents/agent.py:944\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m    942\u001b[0m     raise_error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raise_error:\n\u001b[0;32m--> 944\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    945\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn output parsing error occurred. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    946\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to pass this error back to the agent and have it try \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    947\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magain, pass `handle_parsing_errors=True` to the AgentExecutor. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is the error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    949\u001b[0m     )\n\u001b[1;32m    950\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
      "\u001b[0;31mValueError\u001b[0m: An output parsing error occurred. In order to pass this error back to the agent and have it try again, pass `handle_parsing_errors=True` to the AgentExecutor. This is the error: Could not parse LLM output: `I have successfully extracted the contents of the webpage.\nAction: None`"
     ]
    }
   ],
   "source": [
    "agent.run('Can you extract the contents of this webpage https://techstrong.ai/aiops/the-rise-of-shadow-ai/ and then generate a summary of the extracted text?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b9fd90-7e2d-4477-b948-af8475593e4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
