{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9292d6c9-cc77-439b-b9d6-5195f30c6cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the purpose of this notebook is to try and create a vector DB on the contents of the AI Policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ec7a8d6-32c7-404f-8e3c-42c94f50bedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the beautiful soup loader\n",
    "from langchain.document_loaders import BSHTMLLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d43a649b-171d-46f8-9432-ea49f659375c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how is the doc being embedded\n",
    "from langchain.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d53b25c-b262-4c23-ba79-13cbbd631f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how will text be split?\n",
    "from langchain.text_splitter import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8410bad-955b-4e8f-92eb-1c9038562e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now the database\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d7fd521-5b2c-4a9c-8e4a-27d655e00148",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0b1a40a8-6ad1-40f3-8e11-580839fcb16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first load the document\n",
    "loader = BSHTMLLoader('./policy.html')\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ae696345-857f-4a4e-a35e-adcda5bac472",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain.text_splitter:Created a chunk of size 517, which is longer than the specified 500\n"
     ]
    }
   ],
   "source": [
    "# split the docs into chunks\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=500)\n",
    "split_docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75bc0960-57d1-44e9-abf7-ad524a0d35d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now connect to embedding function\n",
    "embedding_function = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5ad171bc-f233-43b6-8690-3aa56225064d",
   "metadata": {},
   "source": [
    "# now create a vector store\n",
    "db = Chroma.from_documents(\n",
    "    split_docs,\n",
    "    embedding=embedding_function,\n",
    "    persist_directory='.'\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "72d1deae-2528-46f2-8627-207736a382f0",
   "metadata": {},
   "source": [
    "db.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff0e783f-2f6b-4a2a-8315-1357db60dd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load back the doc\n",
    "db_new_connection = Chroma(\n",
    "    persist_directory='.',\n",
    "    embedding_function=embedding_function\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6894bf3-b11c-4630-ac5f-272ce5c057ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " At what size will the government like to regulate the AI model?\n"
     ]
    }
   ],
   "source": [
    "# find similar text first\n",
    "question = input() #'Who and which organizations helped create the policy?'"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1126d23a-3a84-4a1e-9e64-a0c03925015d",
   "metadata": {},
   "source": [
    "similar_docs = db_new_connection.similarity_search(question)\n",
    "print(similar_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f123bb8-e59e-4d25-85b9-987b4707ea0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need a MultiQuery\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9443d7f-2817-45f0-a01a-d6f19834706d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally, connnect the llm and use it for query\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "retriever_from_llm = MultiQueryRetriever.from_llm(\n",
    "    retriever=db_new_connection.as_retriever(),\n",
    "    llm = llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f8c37b4-8f44-4b2f-9424-2251d188d052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get more logging in output\n",
    "# logging behind scenes\n",
    "import logging\n",
    "logging.basicConfig()\n",
    "logging.getLogger('langchain.retrievers.multi_query').setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "749e2522-acb7-4f7f-9cba-ae53c7edd607",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.multi_query:Generated queries: [\"1. What are the government's preferences regarding the regulation of AI models in terms of size?\", '2. How does the government determine the size at which they would like to regulate AI models?', \"3. What factors influence the government's decision to regulate AI models and at what size do they typically intervene?\"]\n"
     ]
    }
   ],
   "source": [
    "# finally execute the chat query and print the result\n",
    "unique_docs = retriever_from_llm.get_relevant_documents(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "609fba7b-c179-4035-9d43-23f50a632523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally, summarize the text that was retrieved\n",
    "matching_docs = ''\n",
    "\n",
    "for doc in unique_docs:\n",
    "    matching_docs += doc.page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6dfa6009-ce9f-4bf0-a5a5-b86195e73c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now execute a new query to LLM\n",
    "from langchain.prompts.chat import SystemMessagePromptTemplate, HumanMessagePromptTemplate, AIMessagePromptTemplate, ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f85f405a-6dd5-4989-8331-ed5548126e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = 'You are an expert and analyzing the given text input and extracting the relevant information. Answer the user question based only the text provided and no external data'\n",
    "system_prompt = SystemMessagePromptTemplate.from_template(system_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d64e7abd-894b-48da-aebe-037fc8678517",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_message = '''Please answer my {question}. Here is the relevant information below: \n",
    "```\n",
    "{relevant_information}\n",
    "```\n",
    "'''\n",
    "human_prompt = HumanMessagePromptTemplate.from_template(human_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "503f18d2-ae62-49b1-b757-27ba1f08c79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([system_prompt, human_prompt])\n",
    "request = chat_prompt.format_prompt(question=question,relevant_information=matching_docs ).to_messages()\n",
    "#print(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0787f619-0ea4-4a0e-91a5-8aa883ccf36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1642c942-5d6f-4575-970f-ac72c22310bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the information provided, the government will like to regulate AI models that pose a serious risk to national security, national economic security, or national public health and safety. Companies developing such AI models will be required to notify the federal government when training the model and share the results of all red-team safety tests. The government will also establish standards, tools, and tests to ensure the safety, security, and trustworthiness of AI systems. Additionally, the government will develop strong new standards for biological synthesis screening to protect against the risks of using AI to engineer dangerous biological materials. The Department of Commerce will establish standards and best practices for detecting AI-generated content and authenticating official content to protect against AI-enabled fraud and deception.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4625b47c-6b9c-453a-b446-a2365694418e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
